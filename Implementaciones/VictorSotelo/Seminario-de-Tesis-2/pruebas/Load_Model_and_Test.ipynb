{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importanción de librerías "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.externals import joblib as joblib\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación de ficheros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función se encarga de generar un archivo txt de manera que este contenga 2 elementos por fila ('name_file','etiqueta') de esta manera permitirá poder entrenar la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "def generate_file_data(dir,name):\n",
    "    directory=dir\n",
    "    #el nombre de los archivos posee el primer dígito en el nombre de esta forma permitirá etiquetarlos.\n",
    "    a={'0':'cero','1':'uno','2':'dos','3':'tres','4':'cuatro','5':'cinco','6':'seis','7':'siete','8':'ocho','9':'nueve'}\n",
    "    da=os.listdir(directory)\n",
    "    # ordena los archivos\n",
    "    da.sort()\n",
    "    file = open(dir+name+'.txt',\"w\")\n",
    "    for filename in da:\n",
    "        if '.wav' in filename:\n",
    "            file.write(filename+','+a[filename[0]]+'\\n')\n",
    "    file.close() \n",
    "    # genera el fichero\n",
    "    with open(directory+'/'+name+'.txt') as f:\n",
    "        read_data = f.read()\n",
    "        f.closed\n",
    "    read_data=read_data.split('\\n')\n",
    "    read_data=read_data[0:len(read_data)-1]\n",
    "    return read_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding words with One Hot Encoding\n",
    "En esta sección se usará one hot encoding para representar las palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot=joblib.load('OneHotEncoding/onehot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se muestran las funciones para codificar y decodificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x):# tomará un array de string y lo transformada a encode\n",
    "    return onehot.transform(x.reshape(-1,1)).toarray()\n",
    "def decode(x):\n",
    "    return onehot.inverse_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_features(DIR,list_dir):\n",
    "    mfcc_audios=[]\n",
    "    for dir in list_dir:\n",
    "        wave, sr = librosa.load(DIR+dir, mono=True)\n",
    "        features= librosa.feature.mfcc(wave, sr,n_mfcc=13)\n",
    "        try:\n",
    "            features=np.pad(features,((0,0),(0,150-len(features[0]))),mode='constant', constant_values=0)\n",
    "        except OSError as err:\n",
    "            print(dir)\n",
    "        mfcc_audios.append(features)\n",
    "    mfcc_audios=np.array(mfcc_audios)\n",
    "    return mfcc_audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(dir,name):\n",
    "    file = open(dir+name)\n",
    "    f=file.read()\n",
    "    file.close()\n",
    "    f=f.split('\\n')\n",
    "    f=f[0:len(f)-1]\n",
    "    labels=[]\n",
    "    names_audios=[]\n",
    "    for i in f:\n",
    "        j=i.split(',')\n",
    "        names_audios.append(j[0])\n",
    "        labels.append(j[1])\n",
    "    labels=np.array(labels)\n",
    "    onehot= encode(labels)\n",
    "    mfcc=mfcc_features(dir,names_audios)\n",
    "    print(name+' OK')\n",
    "    return mfcc,onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se definen los distintos modelos a aplicar en este seminario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se cargará el modelo propuesto para realizar las pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(dir):\n",
    "    m=tf.keras.models.load_model(dir)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('Models/prueba/LSTM950_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recording audios and predict them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import pyaudio\n",
    "import wave\n",
    "import sklearn.externals.joblib as joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(name='prueba'):\n",
    "    generate_file_data('data/pruebas/',name)\n",
    "    data=prepare_data('data/pruebas/',name+'.txt')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prec():\n",
    "    data=prepare()\n",
    "    testx, testy = data[0],data[1]\n",
    "    testx=np.matrix.transpose(testx,[0,2,1])\n",
    "    print(model.evaluate(testx,testy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_number(dir):\n",
    "    onda, sr = librosa.load(dir, mono=True)\n",
    "    features= librosa.feature.mfcc(onda, sr,n_mfcc=13)\n",
    "    features=np.pad(features,((0,0),(0,150-len(features[0]))),mode='constant', constant_values=0)\n",
    "    f=np.matrix.transpose(np.array([features]),[0,2,1])\n",
    "    label=model.predict_classes(f)\n",
    "    texto=decode(np.eye(10)[label])\n",
    "    print(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prueba.txt OK\n",
      "13/13 [==============================] - 0s 32ms/step\n",
      "[1.6168429851531982, 0.6153846383094788]\n"
     ]
    }
   ],
   "source": [
    "test_prec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['nueve']]\n"
     ]
    }
   ],
   "source": [
    "predict_number('data/pruebas/9_prueba_b.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['seis']]\n"
     ]
    }
   ],
   "source": [
    "predict_number('data/pruebas/6_prueba_b.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['dos']]\n"
     ]
    }
   ],
   "source": [
    "predict_number('data/pruebas/1_v_v1.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['cero']]\n"
     ]
    }
   ],
   "source": [
    "predict_number('data/pruebas/1_v_v2.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['cero']]\n"
     ]
    }
   ],
   "source": [
    "predict_number('data/pruebas/1_v_v3.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['dos']]\n"
     ]
    }
   ],
   "source": [
    "predict_number('data/pruebas/2_vi_v1.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['dos']]\n"
     ]
    }
   ],
   "source": [
    "predict_number('data/pruebas/2_vi_v2.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['dos']]\n"
     ]
    }
   ],
   "source": [
    "predict_number('data/pruebas/2_vi_v3.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['tres']]\n"
     ]
    }
   ],
   "source": [
    "predict_number('data/pruebas/3_v_v1.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['tres']]\n"
     ]
    }
   ],
   "source": [
    "predict_number('data/pruebas/3_v_v2.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['tres']]\n"
     ]
    }
   ],
   "source": [
    "predict_number('data/pruebas/3_v_v3.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
